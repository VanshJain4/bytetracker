{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanshJain4/bytetracker/blob/main/bytetracker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EV-10oUCeh2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# 1. Install YOLOv8 (Ultralytics)\n",
        "# =======================\n",
        "!pip install ultralytics --upgrade -q\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "\n",
        "# =======================\n",
        "# 2. Import libraries\n",
        "# =======================\n",
        "import cv2\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Video\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =======================\n",
        "# 3. Upload your input video\n",
        "# =======================\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get uploaded video path\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "# =======================\n",
        "# 4. Load YOLOv8 model (pretrained on COCO)\n",
        "# =======================\n",
        "model = YOLO(\"yolov8n.pt\")  # Options: yolov8n.pt, yolov8s.pt, yolov8m.pt, etc.\n",
        "\n",
        "# =======================\n",
        "# 5. Open input video\n",
        "# =======================\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Output video writer\n",
        "out_path = \"output_people_detected.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
        "\n",
        "# =======================\n",
        "# 6. Process video frame by frame\n",
        "# =======================\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Run YOLOv8 inference\n",
        "    results = model(frame, verbose=False)[0]\n",
        "\n",
        "    # Draw bounding boxes for 'person' class (class_id = 0 in COCO)\n",
        "    for box in results.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        if cls_id == 0:  # person class\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = float(box.conf[0])\n",
        "            label = f'Person {conf:.2f}'\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# =======================\n",
        "# 7. Display the output video\n",
        "# =======================\n",
        "Video(out_path, embed=True)\n"
      ],
      "metadata": {
        "id": "fG91Id9p9ni7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "output_txt_dir = \"yolo_dets\"\n",
        "os.makedirs(output_txt_dir, exist_ok=True)\n",
        "\n",
        "frame_id = 0  # Increment this per frame\n",
        "\n",
        "# Inside your video loop after getting results:\n",
        "detections = []\n",
        "\n",
        "for box in results.boxes:\n",
        "    cls_id = int(box.cls[0])\n",
        "    if cls_id == 0:  # Person class only\n",
        "        x1, y1, x2, y2 = map(float, box.xyxy[0])\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "        conf = float(box.conf[0])\n",
        "        detections.append(f\"{frame_id},{x1:.2f},{y1:.2f},{w:.2f},{h:.2f},{conf:.4f}\")\n",
        "\n",
        "# Write detections to file (append per frame)\n",
        "with open(os.path.join(output_txt_dir, \"results.txt\"), \"a\") as f:\n",
        "    for line in detections:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "frame_id += 1\n"
      ],
      "metadata": {
        "id": "I0IoEBzN9woL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"yolo_dets\", exist_ok=True)\n",
        "\n",
        "def save_detections_for_bytetrack(results, video_name=\"video\", conf_threshold=0.3):\n",
        "    with open(f'yolo_dets/{video_name}.txt', 'w') as f:\n",
        "        for frame_id, result in enumerate(results):\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                cls_id = int(box.cls.cpu().numpy()[0])\n",
        "                if cls_id != 0:  # class 0 = person in COCO\n",
        "                    continue\n",
        "                conf = float(box.conf.cpu().numpy()[0])\n",
        "                if conf < conf_threshold:\n",
        "                    continue\n",
        "                x1, y1, x2, y2 = box.xyxy.cpu().numpy()[0]\n",
        "                w, h = x2 - x1, y2 - y1\n",
        "                f.write(f\"{frame_id+1},{x1},{y1},{w},{h},{conf},-1,-1,-1\\n\")\n",
        "\n",
        "# Pass your YOLOv8 results here\n",
        "save_detections_for_bytetrack(results)\n"
      ],
      "metadata": {
        "id": "a236DfNE93-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Add yolox repo path to Python\n",
        "sys.path.append('/content/ByteTrack-cpp/build/ByteTrack/yolox')  # adjust if needed\n",
        "\n",
        "from yolox.exp import get_exp\n",
        "from yolox.utils import postprocess\n"
      ],
      "metadata": {
        "id": "EfGAPIWz99NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "\n",
        "model = YOLO('/content/yolov8n.pt')\n",
        "\n",
        "# Define a color palette â€” you can assign a unique color to each class id\n",
        "np.random.seed(42)  # for consistent colors\n",
        "num_classes = 80  # COCO dataset classes count, adjust if needed\n",
        "colors = np.random.randint(0, 255, size=(num_classes, 3), dtype=np.uint8)\n",
        "\n",
        "# Optional: Map class IDs to class names (from COCO dataset for YOLOv8)\n",
        "coco_classes = [\n",
        "    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\",\n",
        "    \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\",\n",
        "    \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\",\n",
        "    \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
        "    \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
        "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\",\n",
        "    \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\",\n",
        "    \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\n",
        "    \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
        "    \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV\",\n",
        "    \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\",\n",
        "    \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\",\n",
        "    \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
        "]\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(\"/content/output_people_detected.mp4\")\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = None\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = model(rgb_frame)\n",
        "    result = results[0]\n",
        "\n",
        "    boxes = result.boxes.xyxy.cpu().numpy()\n",
        "    scores = result.boxes.conf.cpu().numpy()\n",
        "    classes = result.boxes.cls.cpu().numpy().astype(int)\n",
        "\n",
        "    for box, score, cls in zip(boxes, scores, classes):\n",
        "        x1, y1, x2, y2 = box.astype(int)\n",
        "        color = tuple(int(c) for c in colors[cls])  # color for this class\n",
        "        class_name = coco_classes[cls] if cls < len(coco_classes) else f\"Class {cls}\"\n",
        "        label = f\"{class_name} {score:.2f}\"\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(frame, label, (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "    if out is None:\n",
        "        height, width = frame.shape[:2]\n",
        "        out = cv2.VideoWriter('/content/output_annotated_better.mp4', fourcc, 30, (width, height))\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"Video saved as /content/output_annotated_better.mp4\")\n"
      ],
      "metadata": {
        "id": "OBTQ3Nbk99yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yolox.tracker.byte_tracker import BYTETracker\n",
        "from yolox.tracker.byte_tracker import STrack\n",
        "import numpy as np\n",
        "np.float = float  # Temporary fix for deprecated np.float usage\n",
        "\n",
        "\n",
        "# ByteTrack arguments (mock basic config)\n",
        "class Args:\n",
        "    track_thresh = 0.5\n",
        "    track_buffer = 30\n",
        "    match_thresh = 0.8\n",
        "    aspect_ratio_thresh = 1.6\n",
        "    min_box_area = 10\n",
        "    mot20 = False\n",
        "\n",
        "args = Args()\n",
        "tracker = BYTETracker(args, frame_rate=30)\n",
        "\n",
        "# Load detections saved to file\n",
        "detections_file = \"yolo_dets/video.txt\"\n",
        "\n",
        "frame_id = 1\n",
        "track_results = []\n",
        "\n",
        "with open(detections_file, 'r') as f:\n",
        "    for line in f:\n",
        "        items = line.strip().split(',')\n",
        "        fid, x1, y1, w, h, score = int(items[0]), float(items[1]), float(items[2]), float(items[3]), float(items[4]), float(items[5])\n",
        "        if fid != frame_id:\n",
        "            online_targets = tracker.update(np.array(track_dets), (height, width), (height, width))\n",
        "            for t in online_targets:\n",
        "                tlwh = t.tlwh\n",
        "                tid = t.track_id\n",
        "                track_results.append(f\"{frame_id},{int(tid)},{tlwh[0]:.2f},{tlwh[1]:.2f},{tlwh[2]:.2f},{tlwh[3]:.2f},1,-1,-1,-1\")\n",
        "            track_dets = []\n",
        "            frame_id = fid\n",
        "        if 'track_dets' not in locals():\n",
        "            track_dets = []\n",
        "        track_dets.append([x1, y1, x1 + w, y1 + h, score])\n",
        "\n",
        "# Optional: save results\n",
        "with open(\"bytetrack_results.txt\", \"w\") as f:\n",
        "    for line in track_results:\n",
        "        f.write(line + \"\\n\")\n"
      ],
      "metadata": {
        "id": "EH_7NXZf9_Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get uploaded video path\n",
        "video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "pSeVMZI7-Dob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloads the yolo object deetection tool but silently\n",
        "!pip install ultralytics --upgrade -q\n",
        "# Install yolox dependencies\n",
        "#fast bouding box utility library\n",
        "!pip install cython-bbox\n",
        "!git clone https://github.com/ifzhang/ByteTrack.git\n",
        "%cd ByteTrack\n",
        "#install bytrtrack dependencies, that are written in requirments.txt\n",
        "!pip install -r requirements.txt\n",
        "#install bytetrack as an editable package, sets up buyetrack so you can use it as a python packaga\n",
        "!python setup.py develop\n"
      ],
      "metadata": {
        "id": "cV-yJlGW-D8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -rnw '/content/ByteTrack' -e 'np.float'\n",
        "!find /content/ByteTrack -type f -name \"*.py\" -exec sed -i 's/np.float/float/g' {} +\n",
        "%cd /content/ByteTrack\n",
        "!python setup.py develop"
      ],
      "metadata": {
        "id": "idqFuG1b-I5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for logging\n",
        "!pip install loguru\n",
        "#needed for assignment problem in tracking algorithm\n",
        "!pip install lap\n",
        "!sed -i 's/float32/np.float32/g' /content/ByteTrack/yolox/utils/visualize.py\n"
      ],
      "metadata": {
        "id": "Wzmzcvf6-L0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import sys\n",
        "\n",
        "# make sure the output folder for yolo detection exists\n",
        "# creates folder yolo_dets oif doesnt\n",
        "os.makedirs(\"yolo_dets\", exist_ok=True)\n",
        "\n",
        "# solution to outpdated numpy code\n",
        "np.float = float\n",
        "\n",
        "# add bytetracker code to python path to import its tracker class\n",
        "sys.path.append('/content/ByteTrack')\n",
        "from yolox.tracker.byte_tracker import BYTETracker\n",
        "\n",
        "# ByteTrack config\n",
        "#track thresh , lowering it jeporidizes the accuracy but also makes sure that more people are detected by bytetracker,\n",
        "# in the current video if yolo detects 13 people with 0.3 you will see 8\n",
        "# detected by bytetracker\n",
        "class Args:\n",
        "    track_thresh = 0.3\n",
        "    track_buffer = 30\n",
        "    match_thresh = 0.8\n",
        "    aspect_ratio_thresh = 1.6\n",
        "    min_box_area = 1\n",
        "    mot20 = False\n",
        "\n",
        "args = Args()\n",
        "tracker = BYTETracker(args, frame_rate=30)\n",
        "\n",
        "# Load YOLOv8 model, a pretrained model\n",
        "model = YOLO('/content/yolov8n.pt')  # Adjust path as needed\n",
        "\n",
        "# Video paths\n",
        "input_video = \"/content/palace.mp4\"  # Change as needed\n",
        "output_video = \"/content/output_tracked.mp4\"\n",
        "output_txt = \"/content/bytetrack_results.txt\"\n",
        "yolo_dets_txt = \"/content/yolo_detections.txt\"\n",
        "\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(input_video)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Video writer for output\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
        "\n",
        "# Prepare colors for drawing\n",
        "np.random.seed(42)\n",
        "colors = np.random.randint(0, 255, size=(1000, 3), dtype=np.uint8)\n",
        "\n",
        "frame_id = 0\n",
        "track_results = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    frame_id += 1\n",
        "\n",
        "    # Run YOLOv8 detection on RGB frame\n",
        "    #dont know what this does not written by me......\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    results = model(rgb_frame)[0]\n",
        "\n",
        "    # Filter detections: person class (0), conf > 0.3\n",
        "    dets = []\n",
        "    for box, score, cls in zip(results.boxes.xyxy.cpu().numpy(),\n",
        "                               results.boxes.conf.cpu().numpy(),\n",
        "                               results.boxes.cls.cpu().numpy().astype(int)):\n",
        "        if cls == 0 and score > 0.3:\n",
        "            x1, y1, x2, y2 = box\n",
        "            dets.append([x1, y1, x2, y2, score])\n",
        "    with open(yolo_dets_txt, \"a\") as f_dets:\n",
        "      for det in dets:\n",
        "        x1, y1, x2, y2, score = det\n",
        "        f_dets.write(f\"{frame_id},{x1:.2f},{y1:.2f},{x2:.2f},{y2:.2f},{score:.3f}\\n\")\n",
        "\n",
        "\n",
        "    if len(dets) == 0:\n",
        "        online_targets = tracker.update(np.empty((0, 5)), (height, width), (height, width))\n",
        "    else:\n",
        "        online_targets = tracker.update(np.array(dets), (height, width), (height, width))\n",
        "\n",
        "    # Draw boxes and IDs\n",
        "    for t in online_targets:\n",
        "        tlwh = t.tlwh\n",
        "        tid = t.track_id\n",
        "        x, y, w, h = map(int, tlwh)\n",
        "        color = tuple(int(c) for c in colors[tid % 1000])\n",
        "\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(frame, f'ID:{tid}', (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "\n",
        "        track_results.append(f\"{frame_id},{tid},{x},{y},{w},{h},1,-1,-1,-1\")\n",
        "\n",
        "    # Write frame to output video\n",
        "    out.write(frame)\n",
        "\n",
        "    # Display live (optional, uncomment if running locally)\n",
        "    # cv2.imshow(\"Tracking\", frame)\n",
        "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    #     break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "# cv2.destroyAllWindows()  # Uncomment if using imshow\n",
        "\n",
        "# Save tracking results\n",
        "with open(output_txt, \"w\") as f:\n",
        "    for line in track_results:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "print(f\"Input video FPS: {fps}\")\n",
        "print(f\"Video resolution: {width}x{height}\")\n",
        "print(f\"Total frames processed: {frame_id}\")\n",
        "print(f\"Tracking done. Video saved to {output_video}\")\n",
        "print(f\"Tracking results saved to {output_txt}\")\n"
      ],
      "metadata": {
        "id": "HvcodwDX-MM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0AAIvUJl-NoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}